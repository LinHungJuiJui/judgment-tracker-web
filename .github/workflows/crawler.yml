name: Judgment Crawler

on:
  schedule:
    - cron: '0 */6 * * *'  # 每 6 小時執行一次
  workflow_dispatch:

jobs:
  crawler:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get -fy install

    - name: Install ChromeDriver
      run: |
        wget -O chromedriver.zip "https://chromedriver.storage.googleapis.com/$(curl -s https://chromedriver.storage.googleapis.com/LATEST_RELEASE)/chromedriver_linux64.zip"
        unzip chromedriver.zip
        sudo mv chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver

    - name: Run crawler
      run: python crawler.py

    - name: Commit updated JSON
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add data/results.json
        git commit -m "update: results.json from crawler"
        git push || echo "No changes to commit"
